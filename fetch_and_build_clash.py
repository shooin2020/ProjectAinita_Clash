import requests
import base64
import logging
from urllib.parse import urlparse, parse_qs, unquote

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

HEADERS = """# ProjectAinita Clash Config
# Generated by fetch_and_build_clash.py"""

def fetch_config(url):
    https_url = url.replace('ssconf://', 'https://')
    logger.info(f"Fetching config from: {https_url}")

    try:
        response = requests.get(https_url, timeout=10)
        response.raise_for_status()
        content = response.text.strip()
        if content.startswith('ss://'):
            logger.info(f"Fetched config for url: {url}")
            return content
        else:
            logger.error(f"Invalid config format from {https_url}: does not start with ss://")
            return None
    except requests.exceptions.RequestException as e:
        logger.error(f"Error fetching {https_url}: {str(e)}")
        return None

def parse_ss_link(ss_link):
    """
    Parses an ss:// link and returns a dict with keys:
    server, port, cipher, password, udp (always True here)
    """

    try:
        if not ss_link.startswith("ss://"):
            logger.error("Not a valid ss:// link")
            return None

        # Remove "ss://" prefix
        ss_body = ss_link[5:]

        # ss link can be in two formats:
        # 1) base64-encoded: ss://base64(cipher:password@host:port)
        # 2) plain: ss://cipher:password@host:port

        # Check if base64 encoded (usually has no '@' before decoding)
        if '@' not in ss_body:
            # base64 part might be before optional "#"
            base64_part = ss_body.split('#')[0]
            # padding for base64
            missing_padding = len(base64_part) % 4
            if missing_padding:
                base64_part += '=' * (4 - missing_padding)
            decoded = base64.urlsafe_b64decode(base64_part).decode('utf-8')
            # decoded is something like "cipher:password@host:port"
            ss_body = decoded
            # Add back any remarks (after #)
            if '#' in ss_link:
                remark = ss_link.split('#', 1)[1]
                ss_body += '#' + remark

        # Now split cipher:password@host:port
        # separate remark (#) if exists
        remark = None
        if '#' in ss_body:
            ss_body, remark = ss_body.split('#', 1)

        userinfo, hostinfo = ss_body.split('@', 1)
        cipher, password = userinfo.split(':', 1)

        # Parse host and port carefully (sometimes port may have query string)
        # Use urlparse to parse
        parsed = urlparse('//' + hostinfo)  # add // to parse netloc correctly
        server = parsed.hostname
        port = parsed.port
        if port is None:
            logger.error(f"Port missing in ss link: {ss_link}")
            return None

        password = unquote(password)

        return {
            "server": server,
            "port": port,
            "cipher": cipher,
            "password": password,
            "udp": True
        }
    except Exception as e:
        logger.error(f"Error parsing ss link {ss_link}: {str(e)}")
        return None

def main():
    urls = [
        "ssconf://ainita.s3.eu-north-1.amazonaws.com/AinitaServer-1.csv",
        "ssconf://ainita.s3.eu-north-1.amazonaws.com/AinitaServer-2.csv",
        "ssconf://ainita.s3.eu-north-1.amazonaws.com/AinitaServer-3.csv",
        "ssconf://ainita.s3.eu-north-1.amazonaws.com/AinitaServer-4.csv"
    ]

    proxies = []

    for idx, url in enumerate(urls, start=1):
        ss_link = fetch_config(url)
        if not ss_link:
            logger.warning(f"Skipping URL {url} due to fetch failure.")
            continue
        proxy = parse_ss_link(ss_link)
        if not proxy:
            logger.warning(f"Skipping URL {url} due to parse failure.")
            continue
        proxy["name"] = f"Server-{idx}"
        proxies.append(proxy)

    if len(proxies) < 4:
        logger.error(f"Only found {len(proxies)} valid proxies, need 4 to proceed. Exiting.")
        exit(1)

    # ساختار نهایی YAML کلش
    import yaml

    clash_config = {
        "proxies": proxies,
        "proxy-groups": [
            {
                "name": "Auto",
                "type": "url-test",
                "proxies": [p["name"] for p in proxies],
                "url": "http://www.gstatic.com/generate_204",
                "interval": 300
            }
        ],
        "rules": [
            "MATCH,Auto"
        ]
    }

    try:
        with open("ProjectAinita_Clash.yaml", "w", encoding="utf-8") as f:
            f.write("# ProjectAinita Clash Config\n")
            yaml.dump(clash_config, f, allow_unicode=True, sort_keys=False)
        logger.info(f"Successfully wrote config with {len(proxies)} proxies to ProjectAinita_Clash.yaml")
    except Exception as e:
        logger.error(f"Error writing YAML file: {str(e)}")
        exit(1)

if __name__ == "__main__":
    main()
